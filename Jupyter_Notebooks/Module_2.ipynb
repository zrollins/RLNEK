{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62126cb2",
   "metadata": {},
   "source": [
    "# Determine non-equilibrium kinetic parameters as a function of applied force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d6151",
   "metadata": {},
   "source": [
    "## Experimental system parameters of the flow chamber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cdcccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/User/RLNEK_tests/Module_2_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-12dde560e782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#change pathway to directory of Trackmate files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/User/RLNEK_tests/Module_2_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m##INPUT the experimental system parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/User/RLNEK_tests/Module_2_test'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats, optimize, special, interpolate\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "#change pathway to directory of Trackmate files\n",
    "os.chdir('/User/RLNEK_tests/Module_2_test')\n",
    "\n",
    "##INPUT the experimental system parameters\n",
    "mu = float(input('Enter fluid viscosity (dyne-s/cm\\u00b2): ')) * 1e-13\n",
    "a = float(input('Enter cell/sphere radius (\\u03BCm): ')) * 1e6\n",
    "d = float(input('Enter critical distance (\\u03BCm): ')) * 1e6\n",
    "L = float(input('Enter receptor-ligand bond length (nm): ')) * 1e3\n",
    "b = float(input('Enter flow chamber height (\\u03BCm): ')) * 1e6\n",
    "b /= 2\n",
    "w = float(input('Enter flow chamber width (\\u03BCm): ')) * 1e6\n",
    "y = a+d #critical disance of cell/sphere from chamber floor\n",
    "\n",
    "#input stopping criteria\n",
    "CCD_FPS = float(input('Enter CCD FPS: '))\n",
    "stop_dist = input(u'Enter maximum displacement (enter for 0.5 \\u03BCm): D_max (\\u03BCm) = ')\n",
    "if stop_dist == '':\n",
    "    stop_dist = float(0.5)\n",
    "else:\n",
    "    stop_dist = float(stop_dist)\n",
    "    \n",
    "t_min_input = input('Enter non-specific binding time (enter for 0.2 seconds): t_min (seconds) = ')\n",
    "if t_min_input == '':\n",
    "    t_min_input = float(0.2)\n",
    "else:\n",
    "    t_min_input = float(t_min_input)\n",
    "    \n",
    "m_r = float(input('Enter cell/sphere site density (sites/\\u03BCm\\u00b2): '))\n",
    "\n",
    "\n",
    "# inter/extrapolation of the speed constant: theoretical prediction of cell/sphere rotational to hydrodynamic velocity\n",
    "da = np.array([0, 1e-8, 1e-7, 1e-6, \n",
    "                1e-5, 1e-4, 1e-3, 0.003202])\n",
    "speed_constants = np.array([0.5676, 0.5556, 0.5539, 0.5518, \n",
    "                            0.5488, 0.5445, 0.5375, 0.5315])\n",
    "fit_func = interpolate.interp1d(da, speed_constants,\n",
    "                                fill_value='extrapolate')\n",
    "\n",
    "speed_const = fit_func(d/a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092314d0",
   "metadata": {},
   "source": [
    "## Input file names of the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% input user data (calculate intrinsic kinetic parameters, bond lifetime, and capture efficiency as function of applied force)\n",
    "track_data = []\n",
    "spots_data = []\n",
    "site_densities = []\n",
    "shear_rates = []\n",
    "forces = []\n",
    "Q_vals = []\n",
    "N_T_vals = []\n",
    "t_min_vals = []\n",
    "\n",
    "while True:\n",
    "    run = str(input('Enter \\\"y\\\" to input data or \\\"n\\\" to execute: ')) \n",
    "    \n",
    "    if run.lower() == 'n':\n",
    "        break\n",
    "    \n",
    "    elif run.lower() == 'y':\n",
    "        \n",
    "        # site density\n",
    "        m_l = float(input('Enter flow chamber site density (sites/\\u03BCm\\u00b2): '))\n",
    "        site_densities.append(m_l)\n",
    "        \n",
    "        # flow rate\n",
    "        Q = input('For flow chamber site density = %f (sites/\\u03BCm\\u00b2), enter flow rates (\\u03BCL/hr), separated by commas and without new lines: ' % m_l)\n",
    "        Q_str = [val.strip() for val in Q.split(',')]\n",
    "        \n",
    "        Q_arr = np.zeros(len(Q_str))\n",
    "        for i in range(len(Q_str)):\n",
    "            # Q_arr[i] = float(Q_str[i])  \n",
    "            # convert from microliter/h to pm^3/s\n",
    "            Q_arr[i] = float(Q_str[i]) * (10**27) / 3600 \n",
    "        \n",
    "        Q_arr_nc = np.zeros(len(Q_str))\n",
    "        for i in range(len(Q_str)):\n",
    "            Q_arr_nc[i] = float(Q_str[i])\n",
    "        Q_vals.append(list(Q_arr_nc))\n",
    "            \n",
    "        # Calculate applied tensile/tether force\n",
    "        f = Q_arr * np.sqrt(a/(2*L)) * (1.7005*9*np.pi*mu*a**2 + 0.9440*6*np.pi*mu*a**2) / (w*b**2)\n",
    "        forces.append(list(f))\n",
    "        \n",
    "        #Calculate shear stress & shear rate\n",
    "        tau = (3*mu*Q_arr) / (2*w*b**2)\n",
    "        shear_rate = tau / mu\n",
    "        shear_rates.append(shear_rate)\n",
    "        \n",
    "        #Input Trackmate \"tracks\" and \"spots\" file(s) for conditions [site density][flow rate][trial]\n",
    "        track_data_sublist = []\n",
    "        spots_data_sublist = []\n",
    "        t_min_sublist = []\n",
    "        N_T_sublist = []\n",
    "        \n",
    "        for i in range(len(Q_arr)):\n",
    "            track_file_name = input('For flow rate = %.2f (\\u03BCL/hr) and flow chamber site density = %f (sites/\\u03BCm\\u00b2), enter name of \"tracks\" file(s) from Trackmate: ' % (Q_arr_nc[i], m_l))\n",
    "            track_file_list = [val.strip() for val in track_file_name.split(',')]\n",
    "            track_file_subsub = []\n",
    "            for j in range(len(track_file_list)):\n",
    "                if '.csv' not in track_file_list[j]:\n",
    "                    track_file_list[j] += '.csv'\n",
    "                \n",
    "                try:\n",
    "                    with open(track_file_list[j], encoding=\"unicode_escape\") as file_open:\n",
    "                        file = file_open.read()\n",
    "                        track_file_subsub.append(track_file_list[j])\n",
    "                \n",
    "                except FileNotFoundError:\n",
    "                    print('Invalid file name.')\n",
    "                    \n",
    "            track_data_sublist.append(track_file_subsub)\n",
    "                \n",
    "            spots_file_name = input('For flow rate = %.2f (\\u03BCL/hr) and flow chamber site density = %f (sites/\\u03BCm\\u00b2), enter name of \"spots\" file(s) from Trackmate: ' % (Q_arr_nc[i], m_l))\n",
    "            spots_file_list = [val.strip() for val in spots_file_name.split(',')]\n",
    "            spots_file_subsub = []\n",
    "            for j in range(len(spots_file_list)):\n",
    "                if '.csv' not in spots_file_list[j]:\n",
    "                    spots_file_list[j] += '.csv'\n",
    "                    \n",
    "                try:\n",
    "                    with open(spots_file_list[j], encoding=\"unicode_escape\") as file_open:\n",
    "                        file = file_open.read()\n",
    "                        spots_file_subsub.append(spots_file_list[j])\n",
    "                \n",
    "                except FileNotFoundError:\n",
    "                    print('Invalid file name.')\n",
    "                    \n",
    "            spots_data_sublist.append(spots_file_subsub)\n",
    "            \n",
    "            N_T_input = input('For each trial of flow rate = %.2f (\\u03BCL/hr) and flow chamber site density = %f (sites/\\u03BCm\\u00b2), enter N_T values(s): ' % (Q_arr_nc[i], m_l))\n",
    "            N_T_str = [val.strip() for val in N_T_input.split(',')]\n",
    "            N_T_subsub = []\n",
    "            \n",
    "            for j in range(len(N_T_str)):\n",
    "                N_T_float = float(N_T_str[j])\n",
    "                N_T_subsub.append(N_T_float)\n",
    "                \n",
    "            N_T_sublist.append(N_T_subsub)\n",
    "        \n",
    "        track_data.append(track_data_sublist)\n",
    "        spots_data.append(spots_data_sublist)\n",
    "        #t_min_vals.append(t_min_sublist)\n",
    "        N_T_vals.append(N_T_sublist)\n",
    "\n",
    "    else:\n",
    "        print('Please enter \\\"y\\\" or \\\"n\\\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd52d42",
   "metadata": {},
   "source": [
    "## Compute displacement and bond lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% calculating k_off\n",
    "u_f_vals = []\n",
    "U_cell_vals = []\n",
    "U_hd_vals = []\n",
    "U_cell_avg_vals = []\n",
    "U_hd_avg_vals = []\n",
    "\n",
    "koff_vals = []\n",
    "koff_trackID_vals = []\n",
    "koff_avg_vals = []\n",
    "koff_error_vals = []\n",
    "\n",
    "Nb_vals = []\n",
    "NbNT_vals = []\n",
    "NbNT_error_vals = []\n",
    "\n",
    "\n",
    "#3-dimensional nested list format:\n",
    "##sub = site density\n",
    "##subsub = site density, flow rate\n",
    "##subsubsub = site density, flow rate, trial\n",
    "## e.g., Nb_vals[site density][flow rate][trial]\n",
    "##AVG and SEM is over all inputted trials for a given condition [site density][flow rate]\n",
    "\n",
    "for m in range(len(track_data)): \n",
    "    u_f_sub = []\n",
    "    U_cell_sub = []\n",
    "    U_hd_sub = []\n",
    "    U_cell_avg_sub = []\n",
    "    U_hd_avg_sub = []\n",
    "    \n",
    "    Nb_vals_sub = []\n",
    "    NbNT_vals_sub = []\n",
    "    NbNT_error_vals_sub = []\n",
    "    \n",
    "    koff_all_sub = []\n",
    "    koff_trackID_vals_sub = []\n",
    "    koff_avg_vals_sub = []\n",
    "    koff_error_vals_sub = []\n",
    "    \n",
    "    for n in range(len(track_data[m])):\n",
    "    #loop for multiple ligand site densities\n",
    "        #critical velocity calculation for filtering tracks\n",
    "        u_f = y*shear_rates[m][n]*(1-(5/16)*(a/y)**3) * 1e-6 # convert back to microns\n",
    "        u_f_sub.append(u_f)\n",
    "        U_cell_subsub = []\n",
    "        U_hd_subsub = []\n",
    "\n",
    "        koff_all_subsub = []\n",
    "        koff_trackID_vals_subsub = []\n",
    "        koff_avg_vals_subsub = []\n",
    "        koff_error_vals_subsub = []\n",
    "        \n",
    "        Nb_vals_subsub = []\n",
    "        NbNT_vals_subsub = []\n",
    "\n",
    "        for p in range(len(track_data[m][n])):\n",
    "        #loop for multiple trials\n",
    "            #extract data into pandas\n",
    "            tracks_raw_data = pd.read_csv(track_data[m][n][p], header=0,skiprows=range(1,4), encoding= 'unicode_escape')\n",
    "            spots_raw_data = pd.read_csv(spots_data[m][n][p], header=0,skiprows=range(1,4), encoding= 'unicode_escape')\n",
    "            \n",
    "            #collect track velocities < critical velocity\n",
    "            filtered_speeds = tracks_raw_data[tracks_raw_data['TRACK_MEAN_SPEED'] < np.absolute(u_f)]\n",
    "            filtered_tracks_list = list(filtered_speeds['TRACK_ID'])\n",
    "            \n",
    "            #collect all trackIDs (with tracks < critical velocity) in spots file\n",
    "            better_tracks = []\n",
    "            trackID = spots_raw_data['TRACK_ID']\n",
    "            particleID = spots_raw_data['ID']\n",
    "            x_pos = spots_raw_data['POSITION_X']\n",
    "            y_pos = spots_raw_data['POSITION_Y']\n",
    "            frame = spots_raw_data['FRAME']\n",
    "            \n",
    "            for i in range(len(filtered_tracks_list)): \n",
    "                for j in range(len(trackID)):\n",
    "                    if trackID[j] == filtered_tracks_list[i]:\n",
    "                        if j != 0:\n",
    "                            if trackID[j-1] != trackID[j]:\n",
    "                                better_tracks.append(trackID[j])\n",
    "                        else:\n",
    "                            better_tracks.append(trackID[j])\n",
    "                            \n",
    "            #collect all particleIDs' data (with trackIDs < critical velocity) in spots file\n",
    "            particleID_new = []\n",
    "            trackID_new = []\n",
    "            x_new = []\n",
    "            y_new = []\n",
    "            frame_new = []\n",
    "            \n",
    "            for i in range(len(better_tracks)):\n",
    "                for j in range(len(trackID)):\n",
    "                    if trackID[j] == better_tracks[i]:\n",
    "                        particleID_new.append(particleID[j])\n",
    "                        trackID_new.append(trackID[j])\n",
    "                        x_new.append(x_pos[j])\n",
    "                        y_new.append(y_pos[j])\n",
    "                        frame_new.append(frame[j])\n",
    "            \n",
    "            #determine filtered particles that meet stopping criteria (D_min, t_min)\n",
    "            #r refers to meeting criteria\n",
    "           \n",
    "            r_pos_x = []\n",
    "            r_pos_y = []\n",
    "            r_trackID = []\n",
    "            r_particleID = []\n",
    "            r_frame = []\n",
    "            \n",
    "            i = 1\n",
    "            i_max = len(trackID_new)\n",
    "            j = 0\n",
    "            \n",
    "            #calculate particle displacement, D\n",
    "            def calc_disp(x0,x,y0,y):\n",
    "                return np.sqrt((x-x0)**2+(y-y0)**2)\n",
    "            \n",
    "            #iterate through frames, calculate D, collect particle data that meet stopping criteria (D_min, t_min)\n",
    "            tmin_frames = math.ceil(t_min_input * CCD_FPS)\n",
    "            while i < i_max-1:\n",
    "                disp1 = calc_disp(x_new[i],x_new[j],y_new[i],y_new[j])\n",
    "                if disp1 <= stop_dist:\n",
    "                    if i-j > tmin_frames:\n",
    "                        r_particleID.append(particleID_new[i])\n",
    "                        r_trackID.append(trackID_new[i])\n",
    "                        r_pos_x.append(x_new[i])\n",
    "                        r_pos_y.append(y_new[i])\n",
    "                        r_frame.append(frame_new[i])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "                    j = i-1\n",
    "            \n",
    "            #stopping events time conversion: (# of frames) -> seconds\n",
    "            #tc = time conversion\n",
    "            tc_particleID = np.array(r_particleID)\n",
    "            tc_trackID = np.array(r_trackID)\n",
    "            tc_frame = np.array(r_frame)\n",
    "            tc_pos_x =np.array(r_pos_x)\n",
    "            tc_pos_y =np.array(r_pos_y)\n",
    "            \n",
    "            #initial parameters\n",
    "            t_total = []\n",
    "            tc_trackID_new = []\n",
    "            i = 1\n",
    "            j = 0\n",
    "            t_tot = 0\n",
    "            \n",
    "            #time conversion\n",
    "            while i < len(tc_trackID):\n",
    "                if tc_trackID[i] == tc_trackID[j]:\n",
    "                    disp2 = calc_disp(tc_pos_x[i],tc_pos_x[j],tc_pos_y[i],tc_pos_y[j])\n",
    "                    if ((tc_frame[i]-tc_frame[j] > 0) and (disp2 <= stop_dist)):\n",
    "                        if  i == len(tc_trackID)-1:\n",
    "                            t_tot += (tc_frame[i] - tc_frame[j])\n",
    "                            t_total.append((t_tot + tmin_frames + 1) / CCD_FPS)\n",
    "                            tc_trackID_new.append(tc_trackID[j])\n",
    "                            t_tot = 0\n",
    "                            j=i  \n",
    "                            i+=1\n",
    "                        else:\n",
    "                            t_tot += (tc_frame[i] - tc_frame[j])\n",
    "                            j=i\n",
    "                            i+=1\n",
    "                    elif ((tc_frame[i]-tc_frame[j] > 0) and (disp2 > stop_dist)):\n",
    "                        t_total.append((t_tot + 1) / CCD_FPS)\n",
    "                        tc_trackID_new.append(tc_trackID[j])\n",
    "                        t_tot = 0\n",
    "                        j=i  \n",
    "                        i+=1\n",
    "                    else:\n",
    "                        t_tot = 0\n",
    "                        j=i\n",
    "                        i+=1\n",
    "                else:\n",
    "                    t_total.append((t_tot + tmin_frames + 1) / CCD_FPS)\n",
    "                    tc_trackID_new.append(tc_trackID[j])\n",
    "                    t_tot=0\n",
    "                    j=i\n",
    "                    i +=1\n",
    "                    \n",
    "            #determine stopping events with unique track IDs, Nb\n",
    "            i = 1\n",
    "            j = 0\n",
    "            k = 0\n",
    "            t_total_unique = []\n",
    "            tc_trackID_unique = []\n",
    "            t_tot = np.array([0])\n",
    "            \n",
    "            while i < len(tc_trackID_new):\n",
    "                if tc_trackID_new[i] != tc_trackID_new[j]:\n",
    "                    tc_trackID_unique.append(tc_trackID_new[j])\n",
    "                    t_tot = np.add(t_tot, t_total[k])\n",
    "      \n",
    "                    t_total_unique.append(t_tot)\n",
    "                    if i == len(tc_trackID_new) - 1:\n",
    "                        tc_trackID_unique.append(tc_trackID_new[i])\n",
    "                        t_total_unique.append(t_total[i])\n",
    "                        \n",
    "                    j = i\n",
    "                    i += 1\n",
    "                    k += 1\n",
    "                    t_tot = np.array([0])   \n",
    "                else:\n",
    "                    t_tot = np.add(t_tot, t_total[k])\n",
    "                    \n",
    "                    if i == len(tc_trackID_new) - 1:\n",
    "                        t_tot = np.add(t_tot, t_total[i])\n",
    "                        tc_trackID_unique.append(tc_trackID_new[i])\n",
    "                        t_total_unique.append(t_tot)\n",
    "   \n",
    "                    i += 1\n",
    "                    k += 1\n",
    "            \n",
    "            #calculate moving time of particles not bound, U_hd (for k+*)\n",
    "            durations_raw = tracks_raw_data['TRACK_DURATION'] # units: seconds\n",
    "            disp_raw = tracks_raw_data['TRACK_DISPLACEMENT'] # units: microns\n",
    "            trackID_raw = tracks_raw_data['TRACK_ID']\n",
    "            track_speeds_raw = tracks_raw_data['TRACK_MEAN_SPEED'] # units: microns/second\n",
    "            \n",
    "            #getting unique track information\n",
    "            tracks_unique_data = tracks_raw_data.loc[(tracks_raw_data['TRACK_ID'].isin(tc_trackID_unique))]\n",
    "            durations_unique = tracks_unique_data['TRACK_DURATION'].reset_index(drop=True)\n",
    "            disp_unique2 = tracks_unique_data['TRACK_DISPLACEMENT'].reset_index(drop=True)\n",
    "            track_speeds_unique =tracks_unique_data['TRACK_MEAN_SPEED'].reset_index(drop=True)\n",
    "            \n",
    "            time_moving_vals = []\n",
    "            durations_sublist = []\n",
    "            disp_unique = []\n",
    "            U_hd_subsubsub = []\n",
    "            U_cell_subsubsub = []\n",
    "            for q in range(len(tc_trackID_unique)):\n",
    "                U_cell = track_speeds_unique[q]\n",
    "                durations_sublist.append(durations_unique[q])\n",
    "                time_moving = durations_unique[q] - t_total_unique[q]\n",
    "                time_moving_vals.append(time_moving)\n",
    "                disp_unique.append(disp_unique2[q])\n",
    "                U_hd = disp_unique2[q] / time_moving_vals[q]\n",
    "                U_hd_subsubsub.append(U_hd)\n",
    "                U_cell_subsubsub.append(U_cell)\n",
    "\n",
    "            #update list of Uhd, Ucell per condition[site density][flow rate][trial]\n",
    "            U_hd_subsubsub = [float(i) for i in U_hd_subsubsub]  #convert np.array to float  \n",
    "            U_hd_subsub.append(U_hd_subsubsub)\n",
    "            U_cell_subsub.append(U_cell_subsubsub)\n",
    "\n",
    "            \n",
    "            #compute k_off = 1/lifetimes\n",
    "            k_off_subsubsub = []\n",
    "            #k_off_subsubsub = np.reciprocal(t_total_unique, where=t_total_unique!=0)\n",
    "            k_off_subsubsub = np.reciprocal(t_total, where=t_total!=0)\n",
    "            k_off_subsubsub = [float(i) for i in k_off_subsubsub]\n",
    "            \n",
    "            #update list of all k_offs per condition [site density][flow rate][trial]\n",
    "            koff_all_subsub.append(k_off_subsubsub)\n",
    "            koff_trackID_vals_subsub.append(tc_trackID_new)\n",
    "\n",
    "            #update list of tracks bound, N_b, per condition [site density][flow rate][trial]\n",
    "            Nb = len(tc_trackID_unique) #number of tracks that meet stop criteria\n",
    "            Nb_vals_subsub.append(Nb)\n",
    "            \n",
    "            #compute and update list of capture efficiency, Nb/NT, per condition [site density][flow rate][trial]\n",
    "            NT = N_T_vals[m][n][p] #input NT values\n",
    "            NbNT_vals_subsub.append(Nb/NT)  #nested list of Nb/NT values for single condition and n TRIALS\n",
    "        \n",
    "        #compute koff, Nb/NT AVG and SEM across all trials [site density][flow rate]\n",
    "        koff_avg_new = np.mean(list(np.concatenate(koff_all_subsub).flat)) #flatten koff list across TRIALS and AVG for [site density][flow rate]\n",
    "        koff_avg_error = stats.sem(list(np.concatenate(koff_all_subsub).flat)) # flatten koff list across TRIALS and SEM for [site density][flow rate]\n",
    "        NbNT_avg_new = np.mean(NbNT_vals_subsub) # AVG Nb/NT across TRIALS for [site density][flow rate]\n",
    "        NbNT_avg_error = stats.sem(NbNT_vals_subsub) #SEM Nb/NT across TRIALS for [site density][flow rate]\n",
    "        \n",
    "        #update lists of AVG and SEM \n",
    "        koff_avg_vals_sub.append(koff_avg_new) #append koff AVG for [site density][flow rate]\n",
    "        koff_error_vals_sub.append(koff_avg_error) #append koff SEM for [site density][flow rate]\n",
    "        NbNT_error_vals_sub.append(NbNT_avg_error) #append Nb/NT AVG for [site density][flow rate]\n",
    "        NbNT_vals_sub.append(NbNT_avg_new) #append Nb/NT SEM for [site density][flow rate]\n",
    "        U_hd_avg_sub.append(np.mean(list(np.concatenate(U_hd_subsub).flat)))  #append Uhd trial flattened AVG for [site density][flow rate]\n",
    "        U_cell_avg_sub.append(np.mean(list(np.concatenate(U_cell_subsub).flat)))  #append Ucell trial flattened AVG for [site density][flow rate]\n",
    "        \n",
    "        #update all values lists\n",
    "        koff_all_sub.append(koff_all_subsub)\n",
    "        koff_trackID_vals_sub.append(koff_trackID_vals_subsub)\n",
    "        Nb_vals_sub.append(Nb_vals_subsub)\n",
    "        U_hd_sub.append(U_hd_subsub)\n",
    "        U_cell_sub.append(U_cell_subsub)\n",
    "\n",
    "    u_f_vals.append(u_f_sub)\n",
    "    U_hd_vals.append(U_hd_sub)\n",
    "    U_cell_vals.append(U_cell_sub)\n",
    "    U_hd_avg_vals.append(U_hd_avg_sub)\n",
    "    U_cell_avg_vals.append(U_cell_avg_sub)\n",
    "    \n",
    "    Nb_vals.append(Nb_vals_sub)\n",
    "    NbNT_vals.append(NbNT_vals_sub)\n",
    "    NbNT_error_vals.append(NbNT_error_vals_sub)\n",
    "    \n",
    "    koff_vals.append(koff_all_sub)\n",
    "    koff_trackID_vals.append(koff_trackID_vals_sub)\n",
    "    koff_avg_vals.append(koff_avg_vals_sub)\n",
    "    koff_error_vals.append(koff_error_vals_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8d80c",
   "metadata": {},
   "source": [
    "## Compute non-equilibrium kinetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d79376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% calculate receptor-ligand non-equilibrium kinetic parameters\n",
    "# %% k_off bond dissociation model (fit to slip or catch-slip equation)\n",
    "# %% k+ effective on-rate (calculate using bond association model and dissociation model)\n",
    "# %% k_in intrinsic reaction rate (fit to Hammer equations that decouple diffusion-kinetics)\n",
    "# %% k+* effective on-rate (cross-validation calculated from cell/sphere velocity)\n",
    "\n",
    "k_b = 0.0138 #boltzmann constant in (J/K)e-21 or (kg*pm*nm)/(K*s^2)\n",
    "temp = 310.15 # biological temperature in  Kelvin\n",
    "\n",
    "#slip_model\n",
    "def slip(x,y):\n",
    "    slope, log_k_off_0 = np.polyfit(x,y,1)\n",
    "    x_B = slope*k_b*temp\n",
    "    k_off_0 = np.exp(log_k_off_0)\n",
    "    return x_B, k_off_0\n",
    "\n",
    "def slip_func(f,x_B,k_off_0):\n",
    "    return k_off_0*np.exp((x_B*f)/(k_b*temp))\n",
    "\n",
    "#catch_slip_model\n",
    "def catch_slip(f,E_21,k_1rup,f_12,k_2rup,x_B):\n",
    "    exp_1 = np.exp(E_21/(k_b*temp))\n",
    "    exp_2 = np.exp(f/f_12)\n",
    "    exp_3 = np.exp((x_B*f)/(k_b*temp))\n",
    "    return (exp_1*k_1rup + exp_2*k_2rup*exp_3) / (exp_1 + exp_2)\n",
    "\n",
    "E_21_list = []\n",
    "k_1rup_list = []\n",
    "f_12_list = []\n",
    "k_2rup_list = []\n",
    "x_B_list_cs = []\n",
    "\n",
    "for i in range(len(forces)):\n",
    "    params, matrix = optimize.curve_fit(catch_slip, forces[i], koff_avg_vals[i], bounds=[0,np.inf])\n",
    "    E_21_list.append(params[0])\n",
    "    k_1rup_list.append(params[1])\n",
    "    f_12_list.append(params[2])\n",
    "    k_2rup_list.append(params[3])\n",
    "    x_B_list_cs.append(params[4])\n",
    "\n",
    "#slip fitting\n",
    "x_B_list_s = []\n",
    "koff_0_list = []\n",
    "\n",
    "for i in range(len(forces)):\n",
    "    x_B_s, koff_0 = slip(forces[i], np.log(koff_avg_vals[i]))\n",
    "    #nonspec_slip_fit = slip_func(forces, x_B_nonspec, koff_0_nonspec)\n",
    "    x_B_list_s.append(x_B_s)\n",
    "    koff_0_list.append(koff_0)\n",
    "    \n",
    "#distinguishing correct bond dissociation model with physical constraint on x_B\n",
    "def compare_x_B(x_B_s_arr, x_B_cs_arr):\n",
    "    \n",
    "    # catch-slip parameters\n",
    "    x_B_cs_final = []\n",
    "    E_21_final = []\n",
    "    k_1rup_final = []\n",
    "    k_2rup_final = []\n",
    "    f_12_final = []\n",
    "    \n",
    "    # slip model parameters\n",
    "    k_off_0_final = []\n",
    "    x_B_slip_final = []\n",
    "    \n",
    "    s_forces = [] # force values (slip)\n",
    "    cs_forces = [] # force values (catch-slip)\n",
    "    s_k_off = [] # k_off values (slip)\n",
    "    cs_k_off = [] # k_off values (catch-slip)\n",
    "\n",
    "    if len(x_B_s_arr) != len(x_B_cs_arr):\n",
    "        print('Arrays must be equal in length.')\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(x_B_cs_arr)):\n",
    "            \n",
    "            # if x_B is outside of a given threshold, the data is slip\n",
    "            if (x_B_cs_arr[i] < 10**(-3)) or (x_B_cs_arr[i] > 10):\n",
    "                x_B_slip_final.append(x_B_s_arr[i])\n",
    "                k_off_0_final.append(koff_0_list[i])\n",
    "                s_forces.append(forces[i])\n",
    "                s_k_off.append(koff_avg_vals[i])\n",
    "              \n",
    "            # if x_B is inside a given threshold, the data is catch-slip\n",
    "            else:\n",
    "                x_B_cs_final.append(x_B_cs_arr[i])\n",
    "                E_21_final.append(E_21_list[i])\n",
    "                k_1rup_final.append(k_1rup_list[i])\n",
    "                k_2rup_final.append(k_2rup_list[i])\n",
    "                f_12_final.append(f_12_list[i])\n",
    "                cs_forces.append(forces[i])\n",
    "                cs_k_off.append(koff_avg_vals[i])\n",
    "        \n",
    "        # all slip\n",
    "        if (len(x_B_slip_final) != 0) and (len(x_B_cs_final) == 0):\n",
    "            return k_off_0_final, x_B_slip_final, s_forces, s_k_off\n",
    "    \n",
    "        # all catch-slip\n",
    "        elif (len(x_B_slip_final) == 0) and (len(x_B_cs_final) != 0):\n",
    "            return x_B_cs_final, E_21_final, k_1rup_final, k_2rup_final, f_12_final, cs_forces, cs_k_off\n",
    "     \n",
    "        elif (len(x_B_slip_final) != 0) and (len(x_B_cs_final) != 0):\n",
    "            return x_B_cs_final, E_21_final, k_1rup_final, k_2rup_final, f_12_final, cs_forces, cs_k_off, k_off_0_final, x_B_slip_final, s_forces, s_k_off\n",
    "\n",
    "#results of distinguishing\n",
    "lists = compare_x_B(x_B_list_s, x_B_list_cs)\n",
    "if len(lists) == 4:\n",
    "    koff_0_vals = lists[0]\n",
    "    x_B_vals = lists[1]\n",
    "    force_vals_s = lists[2]\n",
    "    koff_vals_s = lists[3]\n",
    "    \n",
    "elif len(lists) == 7:\n",
    "    x_B_vals_cs = lists[0]\n",
    "    E_21_vals = lists[1]\n",
    "    k_1rup_vals = lists[2]\n",
    "    k_2rup_vals = lists[3]\n",
    "    f_12_vals = lists[4]\n",
    "    force_vals_cs = lists[5]\n",
    "    koff_vals_cs = lists[6]\n",
    "    \n",
    "elif len(lists) == 11:\n",
    "    x_B_vals_cs = lists[0]\n",
    "    E_21_vals = lists[1]\n",
    "    k_1rup_vals = lists[2]\n",
    "    k_2rup_vals = lists[3]\n",
    "    f_12_vals = lists[4]\n",
    "    force_vals_cs = lists[5]\n",
    "    koff_vals_cs = lists[6]\n",
    "    koff_0_vals = lists[7]\n",
    "    x_B_vals_s = lists[8]\n",
    "    force_vals_s = lists[9]\n",
    "    koff_vals_s = lists[10]\n",
    "    \n",
    "#k+ function\n",
    "def k_plus_func(NbNT, k_off, m_l):\n",
    "    num = NbNT*k_off\n",
    "    dem = m_l*(1-NbNT)\n",
    "    return num/dem\n",
    "\n",
    "#compute k+ over conditions [site density][flow rate]\n",
    "kplus_vals = []\n",
    "for i in range(len(NbNT_vals)):\n",
    "    kplus = k_plus_func(np.array(NbNT_vals[i]),\n",
    "                        koff_avg_vals[i],\n",
    "                        site_densities[i])\n",
    "    #error = stats.sem(kplus)\n",
    "    kplus_vals.append(kplus)\n",
    "   \n",
    "#compute AVG, SEM k+ over conditions [site density]\n",
    "kplus_vals_avg = []\n",
    "kplus_errors = []\n",
    "for i in range(len(kplus_vals[0])):\n",
    "    avg_sublist = [sublist[i] for sublist in kplus_vals]\n",
    "    kplus_vals_avg.append(np.mean(avg_sublist))\n",
    "    kplus_errors.append(stats.sem(avg_sublist))\n",
    "    \n",
    "#compute k_in\n",
    "\n",
    "#set system parameters\n",
    "#D = 0.15 # receptor diffusivity (um^2/s)\n",
    "#alpha = 2 # reactive radius (nm)\n",
    "\n",
    "#input system parameters\n",
    "D = float(input('Enter receptor-ligand diffusivity (\\u03BCm\\u00b2/s): '))  # um^2/s\n",
    "alpha = float(input('Enter ligand reactive radius (nm): ')) * 1e-3 # convert to micron\n",
    "\n",
    "#Peclet number function\n",
    "def Pe_func(u_f_arr,alpha,D):\n",
    "    u_f_arr *= np.asarray(1-speed_const) \n",
    "    Pe = u_f_arr*alpha/D\n",
    "    return Pe\n",
    "\n",
    "#Nusselt number function\n",
    "def Nu_func(Pe):\n",
    "    I_0 = special.iv(0,Pe/2)\n",
    "    K_0 = special.kv(0,Pe/2)\n",
    "    summation_Nu = 0\n",
    "\n",
    "    for n in range(1,100):\n",
    "        I_n = special.iv(n,Pe/2)\n",
    "        K_n = special.kv(n,Pe/2)\n",
    "        summation_Nu += (-1)**n*(I_n/K_n)\n",
    "    Nu = 2*((I_0/K_0) + 2*summation_Nu)\n",
    "    \n",
    "    return Nu\n",
    "\n",
    "#Hammer number function (dimensionless duration time)\n",
    "def lambda_func(Pe):\n",
    "    I_0 = special.iv(0,Pe/2)\n",
    "    I_1 = special.iv(1,Pe/2)\n",
    "    fraction_1 = -I_1**3/I_0\n",
    "    summation_lambda = 0\n",
    "    \n",
    "    for n in range(1,74): # max: 74, otherwise: runtime warning\n",
    "        I_smol = special.iv(n-1,Pe/2)\n",
    "        I_large = special.iv(n+1,Pe/2)\n",
    "        I_n = special.iv(n,Pe/2)\n",
    "        num = I_smol*I_large*(I_smol+I_large)\n",
    "        dem = I_n\n",
    "        summation_lambda += ((-1)**(n+1))*(num/dem)\n",
    "\n",
    "    cap_lambda = (1/Pe)*(fraction_1 + summation_lambda)\n",
    "    \n",
    "    return cap_lambda\n",
    "\n",
    "#Damkohler number function\n",
    "def k_plus_Pe(Pe,delta, Ac):\n",
    "    Nu = Nu_func(Pe)\n",
    "    cap_lambda = lambda_func(Pe)\n",
    "    P = (cap_lambda*delta)/(1+cap_lambda*delta)\n",
    "    return np.pi*m_r*Ac*D*Nu*P\n",
    "\n",
    "#k_in function\n",
    "def k_in_func(alpha,D,delta):\n",
    "    return (delta*D)/alpha**2\n",
    "\n",
    "#compute Pe numbers\n",
    "Pe_vals = []\n",
    "for i in range(len(u_f_vals)):\n",
    "    Pe = []\n",
    "    Pe = Pe_func(u_f_vals[i], alpha, D)\n",
    "    Pe_vals.append(list(Pe))\n",
    "\n",
    "#compute Nu numbers\n",
    "Nu_vals = []\n",
    "for i in range(len(Pe_vals)):\n",
    "    Nu = Nu_func(np.array(Pe_vals[i]))\n",
    "    Nu_vals.append(list(Nu))\n",
    "\n",
    "#compute Ha (lambda) numbers    \n",
    "lambda_vals = []    \n",
    "for i in range(len(Pe_vals)):\n",
    "    lamb = lambda_func(np.array(Pe_vals[i]))\n",
    "    lambda_vals.append(list(lamb))\n",
    "\n",
    "\n",
    "#calculate cell/sphere max contact area\n",
    "Ac_max = 4*np.pi*(a*1e-6)**2\n",
    "delta_vals = []\n",
    "Ac_vals = []\n",
    "\n",
    "#compute Da numbers\n",
    "for i in range(len(Pe_vals)):\n",
    "    params, matrix = optimize.curve_fit(k_plus_Pe, Pe_vals[i], kplus_vals[i], bounds = [[0,0],[np.inf,Ac_max]])\n",
    "    delta_vals.append(params[0])\n",
    "    Ac_vals.append(params[1])\n",
    "\n",
    "#compute k_in for each condition [site density]   \n",
    "kin_vals = []\n",
    "for i in range(len(delta_vals)):\n",
    "    kin = k_in_func(alpha, D, delta_vals[i])\n",
    "    kin_vals.append(kin)\n",
    "\n",
    "#AVG, SEM Ac over conditions [site density]\n",
    "Ac_avg = np.mean(Ac_vals)\n",
    "Ac_err = stats.sem(Ac_vals)\n",
    "\n",
    "#AVG, SEM k_in over conditions [site density]     \n",
    "kin_avg = np.mean(kin_vals)\n",
    "kin_err = stats.sem(kin_vals)\n",
    "\n",
    "# %% k+* validation\n",
    "\n",
    "#k+* function\n",
    "def kplus_star_func(U_hd,U_cell,koff,m_l):\n",
    "    ratio = np.array(U_cell) / np.array(U_hd)\n",
    "    kplus = (np.array(koff)/m_l) * ((1-ratio)/ratio)\n",
    "    return kplus\n",
    "\n",
    "#compute AVG, SEM k+* over conditions [site density][flow rate]\n",
    "kplus_star_vals = []\n",
    "for i in range(len(koff_avg_vals)):\n",
    "    kplus_star = kplus_star_func(U_hd_avg_vals[i], \n",
    "                                 U_cell_avg_vals[i], \n",
    "                                 koff_avg_vals[i],\n",
    "                                 site_densities[i])\n",
    "    kplus_star_vals.append(kplus_star)\n",
    "\n",
    "\n",
    "#compute AVG, SEM k+* over conditions [site density]\n",
    "kplus_star_avg = []\n",
    "kplus_star_errors = []\n",
    "for i in range(len(kplus_star_vals[0])):\n",
    "    avg_sublist = [sublist[i] for sublist in kplus_star_vals]\n",
    "    kplus_star_avg.append(np.mean(avg_sublist))\n",
    "    kplus_star_errors.append(stats.sem(avg_sublist))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58a08f",
   "metadata": {},
   "source": [
    "## Curve fitting for kinetic model: Nb/NT and k_off as a fucntion of force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% curve fitting: k_off, k+, Nb/NT\n",
    "f_fit_vals = np.linspace(forces[0][0], forces[0][-1], 1000)\n",
    "\n",
    "#koff fit function\n",
    "def koff_fit_func(f):\n",
    "    koff_fit = []\n",
    "    for i in range(len(site_densities)):\n",
    "        # slip model\n",
    "        if (len(lists) == 4) or (len(lists) == 11):\n",
    "            koff_s = slip_func(f, x_B_vals_s[i], koff_0_vals[i])\n",
    "            koff_fit.append(koff_s)\n",
    "        \n",
    "        # catch-slip model\n",
    "        elif (len(lists) == 7) or (len(lists) == 11):\n",
    "            koff_cs = catch_slip(f, E_21_vals[i],\n",
    "                                    k_1rup_vals[i],\n",
    "                                    f_12_vals[i],\n",
    "                                    k_2rup_vals[i],\n",
    "                                    x_B_vals_cs[i])\n",
    "            koff_fit.append(koff_cs)\n",
    "    return koff_fit\n",
    "    \n",
    "# koff fit vals barely change\n",
    "koff_fit_vals = koff_fit_func(f_fit_vals)\n",
    "\n",
    "# force to Pe conversion function\n",
    "def f_to_Pe_func(f):\n",
    "    Q = f * np.sqrt((2*L)/a) * ((w*b**2) / (1.7005*9*np.pi*mu*a**2 + 0.9440*6*np.pi*mu*a**2))\n",
    "    tau = (3*mu*Q) / (2*w*b**2)\n",
    "    shear_rate = tau/mu\n",
    "    u_f = (y*10**(-6)) * shear_rate * (1 - (5/16)*(a/y)**3) # u_f in units of um/s\n",
    "    V = u_f * (1-speed_const)\n",
    "    Pe = (V*alpha)/D # alpha, D have um in units\n",
    "    return Pe\n",
    "\n",
    "Pe_fit_vals = f_to_Pe_func(f_fit_vals)\n",
    "\n",
    "#Probability of interaction function w/ fitted parameters\n",
    "def P_in_fit(Pe):\n",
    "    delta = ((alpha**2)*kin_avg)/D\n",
    "    cap_lambda = lambda_func(Pe)\n",
    "    P = (cap_lambda*delta)/(1+cap_lambda*delta)\n",
    "    return P\n",
    "\n",
    "#k+ fit function\n",
    "kplus_fit_vals = Nu_func(Pe_fit_vals)*D*m_r*np.pi*Ac_avg*P_in_fit(Pe_fit_vals)\n",
    "    \n",
    "#NbNT fit function\n",
    "def NbNT_fit_func(f, m_l_arr, koff_fit, kplus_fit):\n",
    "    NbNT_fit = []\n",
    "    for i in range(len(m_l_arr)):\n",
    "        NbNT = (kplus_fit * site_densities[i]) / (kplus_fit * site_densities[i] + koff_fit[i])\n",
    "        NbNT_fit.append(NbNT)\n",
    "        \n",
    "    return NbNT_fit\n",
    "\n",
    "NbNT_fit_vals = NbNT_fit_func(f_fit_vals, site_densities, koff_fit_vals, kplus_fit_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c99ea",
   "metadata": {},
   "source": [
    "## Plot bond lifetime/k_off as a fucntion of applied force with model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% plot: k_off vs f with curve fits\n",
    "\n",
    "#color cycle scale: setting each set of data + fitted curve to a different color \n",
    "colors = iter(cm.rainbow(np.linspace(0, 1, len(site_densities))))\n",
    "        \n",
    "# koff vs f plot\n",
    "\n",
    "for i in range(len(site_densities)):\n",
    "    if (len(lists) == 4) or (len(lists) == 11):\n",
    "        plt.figure(0)\n",
    "        plt.xlabel('Force (pN)')\n",
    "        plt.ylabel(r'$k_{off} (s^{-1})$')\n",
    "        plt.title('Bond Dissociation Model: Slip')\n",
    "        c = next(colors)\n",
    "        plt.scatter(force_vals_s[i], koff_vals_s[i], color=c,\n",
    "                  label=r'Data for $m_l = %d$' u' sites/\\u03BCm\\u00b2'% site_densities[i])\n",
    "        \n",
    "        plt.plot(f_fit_vals, koff_fit_vals[i], color=c,\n",
    "                  label=r'Slip Model for $m_l = %d$' u' sites/\\u03BCm\\u00b2' % site_densities[i])\n",
    "            \n",
    "        # avoid graphing error when only 1 trial is used\n",
    "        for i in range(len(koff_error_vals)):\n",
    "            for j in range(len(koff_error_vals[i])):\n",
    "                if koff_error_vals[i][j] == koff_error_vals[i][j]:\n",
    "                    plt.errorbar(force_vals_s[i][j], koff_vals_s[i][j],\n",
    "                                  yerr=koff_error_vals[i][j],\n",
    "                                  ecolor=c,\n",
    "                                  capsize=5,\n",
    "                                  fmt='none')\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.savefig('slip.png', dpi=300)\n",
    "    \n",
    "    elif (len(lists) == 7) or (len(lists) == 11):\n",
    "        plt.figure(1, figsize=(9,7))\n",
    "        plt.xlabel('Force (pN)')\n",
    "        plt.ylabel(r'$k_{off} (s^{-1})$')\n",
    "        plt.title('Bond Dissociation Model: Catch-Slip')\n",
    "        c = next(colors)\n",
    "        plt.scatter(force_vals_cs[i], koff_vals_cs[i], color=c,\n",
    "                    label=r'Data for $m_l = %d$' u' sites/\\u03BCm\\u00b2'% site_densities[i])\n",
    "        \n",
    "        plt.plot(f_fit_vals, koff_fit_vals[i], color=c,\n",
    "                 label=r'Catch-Slip Model for $m_l = %d$' u' sites/\\u03BCm\\u00b2' % site_densities[i])\n",
    "            \n",
    "        plt.errorbar(force_vals_cs[i], koff_vals_cs[i], yerr=koff_error_vals[i],\n",
    "                    ecolor=c, capsize=5, fmt='none')\n",
    "                    \n",
    "        plt.legend()\n",
    "        plt.savefig('catch_slip.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610e80c",
   "metadata": {},
   "source": [
    "## Plot capture efficient (Nb/NT) as a fucntion of applied force with model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%   plot: Nb/NT vs f and k+ vs f with curve fits\n",
    "\n",
    "# NbNT vs. F plot\n",
    "plt.figure(2)\n",
    "plt.xlabel('Force (pN)')\n",
    "plt.ylabel(r'Capture Efficiency ($N_b / N_T$)')\n",
    "\n",
    "colors = iter(cm.rainbow(np.linspace(0, 1, len(site_densities))))\n",
    "\n",
    "for i in range(len(NbNT_vals)):\n",
    "    c = next(colors)\n",
    "    plt.scatter(forces[i], NbNT_vals[i], color=c, \n",
    "             label=r'$m_l = %d$' u' sites/\\u03BCm\\u00b2' % site_densities[i])\n",
    "    plt.plot(f_fit_vals, NbNT_fit_vals[i], color=c,\n",
    "             label=r'Best-fit: $m_l = %d$' u' sites/\\u03BCm\\u00b2' % site_densities[i])\n",
    "    \n",
    "    plt.errorbar(forces[i], NbNT_vals[i], yerr=NbNT_error_vals[i],\n",
    "                 ecolor=c, fmt='none', capsize=5)\n",
    "    \n",
    "plt.legend()\n",
    "plt.savefig('NbNT.png', dpi=300)\n",
    "    \n",
    "# k+ vs f plot\n",
    "plt.figure(3)\n",
    "plt.xlabel('Force (pN)')\n",
    "plt.ylabel(r'$k_{+}$' u' (\\u03BCm\\u00b2/s)')\n",
    "plt.scatter(forces[0], kplus_vals_avg, color=c, label=r'AVG $m_l$')\n",
    "plt.plot(f_fit_vals, kplus_fit_vals, color=c, label=r'best-fit: $k_+$')\n",
    "plt.errorbar(forces[0], kplus_vals_avg, yerr=kplus_errors, \n",
    "             ecolor=c, capsize=5, fmt='none')\n",
    "plt.legend()\n",
    "plt.savefig('k+.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ccd9a",
   "metadata": {},
   "source": [
    "## Output bond lifetimes/k_off to a spreadsheet with TrackID from Trackmate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f56eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% writing RLNEK koff values with trackID to csv file for all inputed conditions\n",
    "headers = ['Filename', 'koff (1/s)','TRACK_ID']\n",
    "\n",
    "with open('RLNEK_koff.csv', 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(['Module 2: koff values'])\n",
    "    wr.writerow(headers)  \n",
    "    for i in range(len(koff_vals)):\n",
    "        for j in range(len(koff_vals[i])): \n",
    "            for k in range(len(koff_vals[i][j])):\n",
    "                for m in range(len(koff_vals[i][j][k])):\n",
    "                    if m == 0:\n",
    "                        wr.writerow([track_data[i][j][k], koff_vals[i][j][k][m], koff_trackID_vals[i][j][k][m]])\n",
    "                    else:\n",
    "                        wr.writerow(['', koff_vals[i][j][k][m], koff_trackID_vals[i][j][k][m]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14187688",
   "metadata": {},
   "source": [
    "## Output RLNEK summary statistics to a spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% writing RLNEK summary statistics to csv file\n",
    "csv_data = []\n",
    "for i in range(len(site_densities)):\n",
    "    csv_sublist = [] # [filename, force, koff, ...] for each site density\n",
    "    for j in range(len(track_data[i])):\n",
    "        csv_subsub = [track_data[i][j], m_r, site_densities[i], \n",
    "                      Q_vals[i][j], forces[i][j], koff_avg_vals[i][j], koff_error_vals[i][j], NbNT_vals[i][j], \n",
    "                      NbNT_error_vals[i][j], kplus_vals[i][j], kplus_star_vals[i][j]]\n",
    "        \n",
    "        csv_sublist.append(csv_subsub)\n",
    "    \n",
    "    csv_data.append(csv_sublist)\n",
    "    \n",
    "headers = ['Filename', 'm_r (sites/\\u03BCm\\u00b2)', 'm_l (sites/\\u03BCm\\u00b2)', \n",
    "           'Q (\\u03BCL/hr)', 'Force (pN)', 'koff (1/s)', 'koff SEM', 'Nb/NT', \n",
    "           'Nb/NT SEM', 'k+ (\\u03BCm\\u00b2/s)', 'k+* (\\u03BCm\\u00b2/s)']\n",
    "\n",
    "with open('RLNEK.csv', 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(['Module 2'])\n",
    "    wr.writerow(headers)\n",
    "\n",
    "    for i in range(len(csv_data)):\n",
    "        for j in range(len(csv_data[i])):\n",
    "            wr.writerow(csv_data[i][j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
